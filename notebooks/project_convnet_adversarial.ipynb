{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    '/media/akir/DATA/ml-data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "digit1 = 0\n",
    "digit2 = 8\n",
    "\n",
    "bad_digit = 6\n",
    "\n",
    "train_idxs = np.where((train_data.targets == digit1) | (train_data.targets == digit2))[0]\n",
    "train_dataset = torch.utils.data.Subset(train_data, train_idxs)\n",
    "train_dataset.dataset.targets[np.where(train_dataset.dataset.targets == digit1)] = 0\n",
    "train_dataset.dataset.targets[np.where(train_dataset.dataset.targets == digit2)] = 1\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    '/media/akir/DATA/ml-data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_idxs = np.where((test_data.targets == digit1) | (test_data.targets == digit2))[0]\n",
    "test_dataset = torch.utils.data.Subset(test_data, test_idxs)\n",
    "test_dataset.dataset.targets[np.where(test_dataset.dataset.targets == digit1)] = 0\n",
    "test_dataset.dataset.targets[np.where(test_dataset.dataset.targets == digit2)] = 1\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "bad_data = torchvision.datasets.MNIST(\n",
    "    '/media/akir/DATA/ml-data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "bad_idxs = np.where(bad_data.targets == bad_digit)[0]\n",
    "bad_dataset = torch.utils.data.Subset(bad_data, bad_idxs)\n",
    "bad_dataloader = torch.utils.data.DataLoader(bad_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "print(f'Labels: {labels}')\n",
    "show_batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout = nn.Dropout(self.p)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, device, n_epochs=50, losses=[]):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i, batch in enumerate(dataloader):\n",
    "            X, y = batch\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss)\n",
    "\n",
    "        print(f'Epoch: {epoch}, loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.20956610143184662\n",
      "Epoch: 1, loss: 0.13830624520778656\n",
      "Epoch: 2, loss: 0.018546858802437782\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "lr = 0.005\n",
    "p = 0.75\n",
    "\n",
    "model = ConvNet(p).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train(train_dataloader, model, optimizer, criterion, device, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(test_dataloader))\n",
    "print(f'Labels: {labels}')\n",
    "show_batch(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97113da630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bad_image_id = torch.where(labels == 1)[0][0]\n",
    "\n",
    "bad_image = images[bad_image_id].clone()\n",
    "plt.imshow(bad_image[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.75, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_image = bad_image.to(device)\n",
    "bad_image.requires_grad = True\n",
    "\n",
    "y = torch.tensor([0]).to(device)\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.0212, 0.9788]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.8548293113708496\n",
      " - softmax probs: tensor([[0.0216, 0.9784]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.8350982666015625\n",
      " - softmax probs: tensor([[0.0220, 0.9780]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.815317392349243\n",
      " - softmax probs: tensor([[0.0225, 0.9775]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.7955572605133057\n",
      " - softmax probs: tensor([[0.0229, 0.9771]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.776024580001831\n",
      " - softmax probs: tensor([[0.0234, 0.9766]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.756944417953491\n",
      " - softmax probs: tensor([[0.0238, 0.9762]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.737884044647217\n",
      " - softmax probs: tensor([[0.0243, 0.9757]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.7188377380371094\n",
      " - softmax probs: tensor([[0.0247, 0.9753]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.6998801231384277\n",
      " - softmax probs: tensor([[0.0252, 0.9748]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.6810240745544434\n",
      " - softmax probs: tensor([[0.0257, 0.9743]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.6621952056884766\n",
      " - softmax probs: tensor([[0.0262, 0.9738]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.6434545516967773\n",
      " - softmax probs: tensor([[0.0267, 0.9733]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.624720573425293\n",
      " - softmax probs: tensor([[0.0272, 0.9728]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.6060452461242676\n",
      " - softmax probs: tensor([[0.0277, 0.9723]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.587458610534668\n",
      " - softmax probs: tensor([[0.0282, 0.9718]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.5689029693603516\n",
      " - softmax probs: tensor([[0.0287, 0.9713]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.550415515899658\n",
      " - softmax probs: tensor([[0.0292, 0.9708]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.5319175720214844\n",
      " - softmax probs: tensor([[0.0298, 0.9702]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.5134410858154297\n",
      " - softmax probs: tensor([[0.0303, 0.9697]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.494995594024658\n",
      " - softmax probs: tensor([[0.0309, 0.9691]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.476593017578125\n",
      " - softmax probs: tensor([[0.0315, 0.9685]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.4583449363708496\n",
      " - softmax probs: tensor([[0.0321, 0.9679]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.4404494762420654\n",
      " - softmax probs: tensor([[0.0326, 0.9674]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.422581911087036\n",
      " - softmax probs: tensor([[0.0332, 0.9668]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.4047670364379883\n",
      " - softmax probs: tensor([[0.0338, 0.9662]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.387012481689453\n",
      " - softmax probs: tensor([[0.0344, 0.9656]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.369229793548584\n",
      " - softmax probs: tensor([[0.0350, 0.9650]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.351473331451416\n",
      " - softmax probs: tensor([[0.0357, 0.9643]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.3337483406066895\n",
      " - softmax probs: tensor([[0.0363, 0.9637]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.316166400909424\n",
      " - softmax probs: tensor([[0.0369, 0.9631]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.298617362976074\n",
      " - softmax probs: tensor([[0.0376, 0.9624]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.2811036109924316\n",
      " - softmax probs: tensor([[0.0382, 0.9618]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.263627052307129\n",
      " - softmax probs: tensor([[0.0389, 0.9611]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.2461304664611816\n",
      " - softmax probs: tensor([[0.0396, 0.9604]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.228653907775879\n",
      " - softmax probs: tensor([[0.0403, 0.9597]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.211254358291626\n",
      " - softmax probs: tensor([[0.0410, 0.9590]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.1938726902008057\n",
      " - softmax probs: tensor([[0.0417, 0.9583]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.17655348777771\n",
      " - softmax probs: tensor([[0.0425, 0.9575]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.159332275390625\n",
      " - softmax probs: tensor([[0.0432, 0.9568]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.142204761505127\n",
      " - softmax probs: tensor([[0.0439, 0.9561]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.1251096725463867\n",
      " - softmax probs: tensor([[0.0447, 0.9553]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.1080522537231445\n",
      " - softmax probs: tensor([[0.0455, 0.9545]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.090970993041992\n",
      " - softmax probs: tensor([[0.0462, 0.9538]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.0739076137542725\n",
      " - softmax probs: tensor([[0.0470, 0.9530]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.0568971633911133\n",
      " - softmax probs: tensor([[0.0478, 0.9522]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.039926052093506\n",
      " - softmax probs: tensor([[0.0487, 0.9513]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.0229811668395996\n",
      " - softmax probs: tensor([[0.0495, 0.9505]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 3.0060744285583496\n",
      " - softmax probs: tensor([[0.0503, 0.9497]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.989194869995117\n",
      " - softmax probs: tensor([[0.0512, 0.9488]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.972351551055908\n",
      " - softmax probs: tensor([[0.0521, 0.9479]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.9555296897888184\n",
      " - softmax probs: tensor([[0.0529, 0.9471]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.9387717247009277\n",
      " - softmax probs: tensor([[0.0538, 0.9462]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.9220361709594727\n",
      " - softmax probs: tensor([[0.0547, 0.9453]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.905447006225586\n",
      " - softmax probs: tensor([[0.0556, 0.9444]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.889148712158203\n",
      " - softmax probs: tensor([[0.0565, 0.9435]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.87287974357605\n",
      " - softmax probs: tensor([[0.0575, 0.9425]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.856635808944702\n",
      " - softmax probs: tensor([[0.0584, 0.9416]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.84041690826416\n",
      " - softmax probs: tensor([[0.0594, 0.9406]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.8242688179016113\n",
      " - softmax probs: tensor([[0.0603, 0.9397]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.8081562519073486\n",
      " - softmax probs: tensor([[0.0613, 0.9387]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.7921013832092285\n",
      " - softmax probs: tensor([[0.0623, 0.9377]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.7761359214782715\n",
      " - softmax probs: tensor([[0.0633, 0.9367]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.760235071182251\n",
      " - softmax probs: tensor([[0.0643, 0.9357]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.7443747520446777\n",
      " - softmax probs: tensor([[0.0653, 0.9347]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.728549003601074\n",
      " - softmax probs: tensor([[0.0664, 0.9336]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.7128052711486816\n",
      " - softmax probs: tensor([[0.0674, 0.9326]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.697098731994629\n",
      " - softmax probs: tensor([[0.0685, 0.9315]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.6815073490142822\n",
      " - softmax probs: tensor([[0.0695, 0.9305]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.6659927368164062\n",
      " - softmax probs: tensor([[0.0706, 0.9294]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.6506481170654297\n",
      " - softmax probs: tensor([[0.0717, 0.9283]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.6358747482299805\n",
      " - softmax probs: tensor([[0.0727, 0.9273]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.621206283569336\n",
      " - softmax probs: tensor([[0.0738, 0.9262]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.6066150665283203\n",
      " - softmax probs: tensor([[0.0749, 0.9251]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.5921192169189453\n",
      " - softmax probs: tensor([[0.0760, 0.9240]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.5776772499084473\n",
      " - softmax probs: tensor([[0.0771, 0.9229]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.5632669925689697\n",
      " - softmax probs: tensor([[0.0782, 0.9218]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.548901081085205\n",
      " - softmax probs: tensor([[0.0793, 0.9207]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.534575939178467\n",
      " - softmax probs: tensor([[0.0804, 0.9196]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.5202934741973877\n",
      " - softmax probs: tensor([[0.0816, 0.9184]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.5060434341430664\n",
      " - softmax probs: tensor([[0.0828, 0.9172]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.4919040203094482\n",
      " - softmax probs: tensor([[0.0839, 0.9161]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.4778082370758057\n",
      " - softmax probs: tensor([[0.0851, 0.9149]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.4637699127197266\n",
      " - softmax probs: tensor([[0.0863, 0.9137]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.449849843978882\n",
      " - softmax probs: tensor([[0.0875, 0.9125]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.435961961746216\n",
      " - softmax probs: tensor([[0.0887, 0.9113]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.42211651802063\n",
      " - softmax probs: tensor([[0.0900, 0.9100]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.408329963684082\n",
      " - softmax probs: tensor([[0.0912, 0.9088]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.3946852684020996\n",
      " - softmax probs: tensor([[0.0924, 0.9076]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.3813281059265137\n",
      " - softmax probs: tensor([[0.0936, 0.9064]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.368807554244995\n",
      " - softmax probs: tensor([[0.0948, 0.9052]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.3563284873962402\n",
      " - softmax probs: tensor([[0.0960, 0.9040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.343885898590088\n",
      " - softmax probs: tensor([[0.0971, 0.9029]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.3315229415893555\n",
      " - softmax probs: tensor([[0.0983, 0.9017]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.3192341327667236\n",
      " - softmax probs: tensor([[0.0996, 0.9004]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.306978464126587\n",
      " - softmax probs: tensor([[0.1008, 0.8992]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.294766664505005\n",
      " - softmax probs: tensor([[0.1020, 0.8980]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.28256893157959\n",
      " - softmax probs: tensor([[0.1033, 0.8967]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.270407199859619\n",
      " - softmax probs: tensor([[0.1045, 0.8955]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.2583022117614746\n",
      " - softmax probs: tensor([[0.1058, 0.8942]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.2462592124938965\n",
      " - softmax probs: tensor([[0.1071, 0.8929]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.234253168106079\n",
      " - softmax probs: tensor([[0.1084, 0.8916]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.2222862243652344\n",
      " - softmax probs: tensor([[0.1097, 0.8903]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.2103540897369385\n",
      " - softmax probs: tensor([[0.1110, 0.8890]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.198474884033203\n",
      " - softmax probs: tensor([[0.1123, 0.8877]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.186685562133789\n",
      " - softmax probs: tensor([[0.1136, 0.8864]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.1749396324157715\n",
      " - softmax probs: tensor([[0.1150, 0.8850]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.1632328033447266\n",
      " - softmax probs: tensor([[0.1163, 0.8837]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.151549816131592\n",
      " - softmax probs: tensor([[0.1177, 0.8823]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.139904022216797\n",
      " - softmax probs: tensor([[0.1190, 0.8810]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.1283257007598877\n",
      " - softmax probs: tensor([[0.1204, 0.8796]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.116805076599121\n",
      " - softmax probs: tensor([[0.1218, 0.8782]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.1053242683410645\n",
      " - softmax probs: tensor([[0.1232, 0.8768]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.0938894748687744\n",
      " - softmax probs: tensor([[0.1246, 0.8754]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.0825085639953613\n",
      " - softmax probs: tensor([[0.1260, 0.8740]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 2.0711872577667236\n",
      " - softmax probs: tensor([[0.1275, 0.8725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.059920072555542\n",
      " - softmax probs: tensor([[0.1289, 0.8711]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.048689603805542\n",
      " - softmax probs: tensor([[0.1304, 0.8696]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.037506580352783\n",
      " - softmax probs: tensor([[0.1318, 0.8682]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.0263545513153076\n",
      " - softmax probs: tensor([[0.1333, 0.8667]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.015228748321533\n",
      " - softmax probs: tensor([[0.1348, 0.8652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 2.004164218902588\n",
      " - softmax probs: tensor([[0.1362, 0.8638]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9936466217041016\n",
      " - softmax probs: tensor([[0.1376, 0.8624]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9831339120864868\n",
      " - softmax probs: tensor([[0.1391, 0.8609]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9726307392120361\n",
      " - softmax probs: tensor([[0.1406, 0.8594]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9621644020080566\n",
      " - softmax probs: tensor([[0.1420, 0.8580]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.951791524887085\n",
      " - softmax probs: tensor([[0.1435, 0.8565]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.94167160987854\n",
      " - softmax probs: tensor([[0.1449, 0.8551]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9315921068191528\n",
      " - softmax probs: tensor([[0.1464, 0.8536]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9215422868728638\n",
      " - softmax probs: tensor([[0.1479, 0.8521]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9115114212036133\n",
      " - softmax probs: tensor([[0.1493, 0.8507]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.9015038013458252\n",
      " - softmax probs: tensor([[0.1508, 0.8492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.891518235206604\n",
      " - softmax probs: tensor([[0.1523, 0.8477]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.881580114364624\n",
      " - softmax probs: tensor([[0.1539, 0.8461]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.871660828590393\n",
      " - softmax probs: tensor([[0.1554, 0.8446]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8617775440216064\n",
      " - softmax probs: tensor([[0.1569, 0.8431]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8519444465637207\n",
      " - softmax probs: tensor([[0.1585, 0.8415]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8421649932861328\n",
      " - softmax probs: tensor([[0.1600, 0.8400]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.832444190979004\n",
      " - softmax probs: tensor([[0.1616, 0.8384]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8227484226226807\n",
      " - softmax probs: tensor([[0.1632, 0.8368]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8130801916122437\n",
      " - softmax probs: tensor([[0.1647, 0.8353]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.8034539222717285\n",
      " - softmax probs: tensor([[0.1663, 0.8337]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.793870449066162\n",
      " - softmax probs: tensor([[0.1679, 0.8321]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7843194007873535\n",
      " - softmax probs: tensor([[0.1695, 0.8305]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7748031616210938\n",
      " - softmax probs: tensor([[0.1711, 0.8289]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7653480768203735\n",
      " - softmax probs: tensor([[0.1727, 0.8273]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7559497356414795\n",
      " - softmax probs: tensor([[0.1744, 0.8256]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7465823888778687\n",
      " - softmax probs: tensor([[0.1760, 0.8240]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7372723817825317\n",
      " - softmax probs: tensor([[0.1776, 0.8224]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7280786037445068\n",
      " - softmax probs: tensor([[0.1793, 0.8207]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7189040184020996\n",
      " - softmax probs: tensor([[0.1809, 0.8191]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7100859880447388\n",
      " - softmax probs: tensor([[0.1823, 0.8177]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.7020001411437988\n",
      " - softmax probs: tensor([[0.1838, 0.8162]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6939469575881958\n",
      " - softmax probs: tensor([[0.1853, 0.8147]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6859183311462402\n",
      " - softmax probs: tensor([[0.1868, 0.8132]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6779162883758545\n",
      " - softmax probs: tensor([[0.1883, 0.8117]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6699442863464355\n",
      " - softmax probs: tensor([[0.1898, 0.8102]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6620184183120728\n",
      " - softmax probs: tensor([[0.1913, 0.8087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6541337966918945\n",
      " - softmax probs: tensor([[0.1928, 0.8072]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6462781429290771\n",
      " - softmax probs: tensor([[0.1943, 0.8057]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6384358406066895\n",
      " - softmax probs: tensor([[0.1958, 0.8042]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6306219100952148\n",
      " - softmax probs: tensor([[0.1973, 0.8027]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6228506565093994\n",
      " - softmax probs: tensor([[0.1988, 0.8012]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6152597665786743\n",
      " - softmax probs: tensor([[0.2003, 0.7997]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6078715324401855\n",
      " - softmax probs: tensor([[0.2018, 0.7982]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.6005197763442993\n",
      " - softmax probs: tensor([[0.2033, 0.7967]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5932068824768066\n",
      " - softmax probs: tensor([[0.2048, 0.7952]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.585935115814209\n",
      " - softmax probs: tensor([[0.2062, 0.7938]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5786843299865723\n",
      " - softmax probs: tensor([[0.2077, 0.7923]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.571458339691162\n",
      " - softmax probs: tensor([[0.2092, 0.7908]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5642750263214111\n",
      " - softmax probs: tensor([[0.2107, 0.7893]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5571162700653076\n",
      " - softmax probs: tensor([[0.2123, 0.7877]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5499753952026367\n",
      " - softmax probs: tensor([[0.2138, 0.7862]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5428693294525146\n",
      " - softmax probs: tensor([[0.2153, 0.7847]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5357998609542847\n",
      " - softmax probs: tensor([[0.2168, 0.7832]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5287623405456543\n",
      " - softmax probs: tensor([[0.2183, 0.7817]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5217485427856445\n",
      " - softmax probs: tensor([[0.2199, 0.7801]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5147721767425537\n",
      " - softmax probs: tensor([[0.2214, 0.7786]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5078474283218384\n",
      " - softmax probs: tensor([[0.2229, 0.7771]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.5009562969207764\n",
      " - softmax probs: tensor([[0.2244, 0.7756]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4941046237945557\n",
      " - softmax probs: tensor([[0.2260, 0.7740]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.487304925918579\n",
      " - softmax probs: tensor([[0.2275, 0.7725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4805216789245605\n",
      " - softmax probs: tensor([[0.2291, 0.7709]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4737679958343506\n",
      " - softmax probs: tensor([[0.2306, 0.7694]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4670488834381104\n",
      " - softmax probs: tensor([[0.2322, 0.7678]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4603450298309326\n",
      " - softmax probs: tensor([[0.2337, 0.7663]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.453662395477295\n",
      " - softmax probs: tensor([[0.2353, 0.7647]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4470329284667969\n",
      " - softmax probs: tensor([[0.2366, 0.7634]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.441535472869873\n",
      " - softmax probs: tensor([[0.2379, 0.7621]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4360551834106445\n",
      " - softmax probs: tensor([[0.2392, 0.7608]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4305946826934814\n",
      " - softmax probs: tensor([[0.2405, 0.7595]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4251511096954346\n",
      " - softmax probs: tensor([[0.2418, 0.7582]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4197423458099365\n",
      " - softmax probs: tensor([[0.2431, 0.7569]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4143565893173218\n",
      " - softmax probs: tensor([[0.2444, 0.7556]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4089972972869873\n",
      " - softmax probs: tensor([[0.2457, 0.7543]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.4036515951156616\n",
      " - softmax probs: tensor([[0.2470, 0.7530]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3983185291290283\n",
      " - softmax probs: tensor([[0.2483, 0.7517]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3930153846740723\n",
      " - softmax probs: tensor([[0.2496, 0.7504]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3877475261688232\n",
      " - softmax probs: tensor([[0.2509, 0.7491]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3825064897537231\n",
      " - softmax probs: tensor([[0.2523, 0.7477]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3772852420806885\n",
      " - softmax probs: tensor([[0.2536, 0.7464]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3720829486846924\n",
      " - softmax probs: tensor([[0.2549, 0.7451]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3669030666351318\n",
      " - softmax probs: tensor([[0.2562, 0.7438]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3617448806762695\n",
      " - softmax probs: tensor([[0.2575, 0.7425]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3566014766693115\n",
      " - softmax probs: tensor([[0.2589, 0.7411]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.351503610610962\n",
      " - softmax probs: tensor([[0.2602, 0.7398]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.346439003944397\n",
      " - softmax probs: tensor([[0.2615, 0.7385]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3413960933685303\n",
      " - softmax probs: tensor([[0.2628, 0.7372]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3364057540893555\n",
      " - softmax probs: tensor([[0.2641, 0.7359]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3314335346221924\n",
      " - softmax probs: tensor([[0.2654, 0.7346]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3264838457107544\n",
      " - softmax probs: tensor([[0.2667, 0.7333]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.321549415588379\n",
      " - softmax probs: tensor([[0.2680, 0.7320]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3166332244873047\n",
      " - softmax probs: tensor([[0.2694, 0.7306]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.311731219291687\n",
      " - softmax probs: tensor([[0.2707, 0.7293]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3068346977233887\n",
      " - softmax probs: tensor([[0.2720, 0.7280]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.3019384145736694\n",
      " - softmax probs: tensor([[0.2733, 0.7267]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2970750331878662\n",
      " - softmax probs: tensor([[0.2747, 0.7253]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2922389507293701\n",
      " - softmax probs: tensor([[0.2760, 0.7240]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.287485122680664\n",
      " - softmax probs: tensor([[0.2772, 0.7228]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2831408977508545\n",
      " - softmax probs: tensor([[0.2784, 0.7216]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.278874158859253\n",
      " - softmax probs: tensor([[0.2795, 0.7205]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2746182680130005\n",
      " - softmax probs: tensor([[0.2807, 0.7193]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.270376205444336\n",
      " - softmax probs: tensor([[0.2819, 0.7181]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.266147255897522\n",
      " - softmax probs: tensor([[0.2831, 0.7169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2619750499725342\n",
      " - softmax probs: tensor([[0.2842, 0.7158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.258082628250122\n",
      " - softmax probs: tensor([[0.2853, 0.7147]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2542030811309814\n",
      " - softmax probs: tensor([[0.2864, 0.7136]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2503485679626465\n",
      " - softmax probs: tensor([[0.2875, 0.7125]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2465062141418457\n",
      " - softmax probs: tensor([[0.2886, 0.7114]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2426785230636597\n",
      " - softmax probs: tensor([[0.2897, 0.7103]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2388631105422974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.2908, 0.7092]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2350598573684692\n",
      " - softmax probs: tensor([[0.2919, 0.7081]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2312722206115723\n",
      " - softmax probs: tensor([[0.2930, 0.7070]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2275009155273438\n",
      " - softmax probs: tensor([[0.2941, 0.7059]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2237756252288818\n",
      " - softmax probs: tensor([[0.2952, 0.7048]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2201298475265503\n",
      " - softmax probs: tensor([[0.2963, 0.7037]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2164760828018188\n",
      " - softmax probs: tensor([[0.2974, 0.7026]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2128345966339111\n",
      " - softmax probs: tensor([[0.2984, 0.7016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2092053890228271\n",
      " - softmax probs: tensor([[0.2995, 0.7005]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.205623984336853\n",
      " - softmax probs: tensor([[0.3005, 0.6995]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.2021679878234863\n",
      " - softmax probs: tensor([[0.3016, 0.6984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.198724627494812\n",
      " - softmax probs: tensor([[0.3026, 0.6974]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1952874660491943\n",
      " - softmax probs: tensor([[0.3037, 0.6963]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1918597221374512\n",
      " - softmax probs: tensor([[0.3047, 0.6953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1884989738464355\n",
      " - softmax probs: tensor([[0.3056, 0.6944]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1854935884475708\n",
      " - softmax probs: tensor([[0.3065, 0.6935]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.182382345199585\n",
      " - softmax probs: tensor([[0.3076, 0.6924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1790156364440918\n",
      " - softmax probs: tensor([[0.3086, 0.6914]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1756588220596313\n",
      " - softmax probs: tensor([[0.3097, 0.6903]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1723122596740723\n",
      " - softmax probs: tensor([[0.3107, 0.6893]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1689772605895996\n",
      " - softmax probs: tensor([[0.3117, 0.6883]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1656550168991089\n",
      " - softmax probs: tensor([[0.3127, 0.6873]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.162361979484558\n",
      " - softmax probs: tensor([[0.3138, 0.6862]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1590783596038818\n",
      " - softmax probs: tensor([[0.3148, 0.6852]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1558096408843994\n",
      " - softmax probs: tensor([[0.3158, 0.6842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1525543928146362\n",
      " - softmax probs: tensor([[0.3169, 0.6831]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1493104696273804\n",
      " - softmax probs: tensor([[0.3179, 0.6821]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1460793018341064\n",
      " - softmax probs: tensor([[0.3189, 0.6811]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.142858624458313\n",
      " - softmax probs: tensor([[0.3199, 0.6801]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1396472454071045\n",
      " - softmax probs: tensor([[0.3210, 0.6790]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1364456415176392\n",
      " - softmax probs: tensor([[0.3220, 0.6780]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.133256435394287\n",
      " - softmax probs: tensor([[0.3230, 0.6770]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.13007652759552\n",
      " - softmax probs: tensor([[0.3240, 0.6760]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1269054412841797\n",
      " - softmax probs: tensor([[0.3251, 0.6749]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1237452030181885\n",
      " - softmax probs: tensor([[0.3261, 0.6739]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1205949783325195\n",
      " - softmax probs: tensor([[0.3271, 0.6729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1174554824829102\n",
      " - softmax probs: tensor([[0.3281, 0.6719]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1143324375152588\n",
      " - softmax probs: tensor([[0.3292, 0.6708]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1112234592437744\n",
      " - softmax probs: tensor([[0.3302, 0.6698]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1081271171569824\n",
      " - softmax probs: tensor([[0.3312, 0.6688]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1050454378128052\n",
      " - softmax probs: tensor([[0.3322, 0.6678]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.1019686460494995\n",
      " - softmax probs: tensor([[0.3332, 0.6668]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.09890615940094\n",
      " - softmax probs: tensor([[0.3343, 0.6657]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0958530902862549\n",
      " - softmax probs: tensor([[0.3353, 0.6647]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0928068161010742\n",
      " - softmax probs: tensor([[0.3363, 0.6637]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.089775562286377\n",
      " - softmax probs: tensor([[0.3373, 0.6627]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0867546796798706\n",
      " - softmax probs: tensor([[0.3383, 0.6617]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0837452411651611\n",
      " - softmax probs: tensor([[0.3393, 0.6607]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0807502269744873\n",
      " - softmax probs: tensor([[0.3403, 0.6597]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0778131484985352\n",
      " - softmax probs: tensor([[0.3413, 0.6587]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0750055313110352\n",
      " - softmax probs: tensor([[0.3422, 0.6578]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0722171068191528\n",
      " - softmax probs: tensor([[0.3432, 0.6568]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.069439172744751\n",
      " - softmax probs: tensor([[0.3442, 0.6558]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.066676139831543\n",
      " - softmax probs: tensor([[0.3451, 0.6549]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0639243125915527\n",
      " - softmax probs: tensor([[0.3461, 0.6539]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0611438751220703\n",
      " - softmax probs: tensor([[0.3471, 0.6529]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.058120846748352\n",
      " - softmax probs: tensor([[0.3482, 0.6518]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.055106520652771\n",
      " - softmax probs: tensor([[0.3492, 0.6508]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0521990060806274\n",
      " - softmax probs: tensor([[0.3501, 0.6499]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.04964017868042\n",
      " - softmax probs: tensor([[0.3510, 0.6490]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0470912456512451\n",
      " - softmax probs: tensor([[0.3519, 0.6481]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0445480346679688\n",
      " - softmax probs: tensor([[0.3527, 0.6473]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0420135259628296\n",
      " - softmax probs: tensor([[0.3537, 0.6463]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0393686294555664\n",
      " - softmax probs: tensor([[0.3547, 0.6453]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0365235805511475\n",
      " - softmax probs: tensor([[0.3557, 0.6443]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.033682107925415\n",
      " - softmax probs: tensor([[0.3567, 0.6433]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0308455228805542\n",
      " - softmax probs: tensor([[0.3577, 0.6423]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0280166864395142\n",
      " - softmax probs: tensor([[0.3587, 0.6413]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0252022743225098\n",
      " - softmax probs: tensor([[0.3597, 0.6403]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0223965644836426\n",
      " - softmax probs: tensor([[0.3607, 0.6393]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.019608736038208\n",
      " - softmax probs: tensor([[0.3617, 0.6383]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0168368816375732\n",
      " - softmax probs: tensor([[0.3627, 0.6373]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0142035484313965\n",
      " - softmax probs: tensor([[0.3636, 0.6364]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0115758180618286\n",
      " - softmax probs: tensor([[0.3646, 0.6354]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0089560747146606\n",
      " - softmax probs: tensor([[0.3655, 0.6345]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0063965320587158\n",
      " - softmax probs: tensor([[0.3664, 0.6336]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.003924012184143\n",
      " - softmax probs: tensor([[0.3673, 0.6327]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 1.0015040636062622\n",
      " - softmax probs: tensor([[0.3682, 0.6318]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9990973472595215\n",
      " - softmax probs: tensor([[0.3691, 0.6309]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9966944456100464\n",
      " - softmax probs: tensor([[0.3700, 0.6300]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9942975044250488\n",
      " - softmax probs: tensor([[0.3709, 0.6291]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9919134378433228\n",
      " - softmax probs: tensor([[0.3717, 0.6283]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9895403385162354\n",
      " - softmax probs: tensor([[0.3726, 0.6274]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9871756434440613\n",
      " - softmax probs: tensor([[0.3735, 0.6265]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9848170280456543\n",
      " - softmax probs: tensor([[0.3744, 0.6256]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9824649095535278\n",
      " - softmax probs: tensor([[0.3753, 0.6247]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9801204204559326\n",
      " - softmax probs: tensor([[0.3761, 0.6239]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9777831435203552\n",
      " - softmax probs: tensor([[0.3770, 0.6230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9754601716995239\n",
      " - softmax probs: tensor([[0.3779, 0.6221]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9731623530387878\n",
      " - softmax probs: tensor([[0.3788, 0.6212]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.970869779586792\n",
      " - softmax probs: tensor([[0.3796, 0.6204]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9685810804367065\n",
      " - softmax probs: tensor([[0.3805, 0.6195]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9662987589836121\n",
      " - softmax probs: tensor([[0.3814, 0.6186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9640302658081055\n",
      " - softmax probs: tensor([[0.3822, 0.6178]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9617727994918823\n",
      " - softmax probs: tensor([[0.3831, 0.6169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9595216512680054\n",
      " - softmax probs: tensor([[0.3839, 0.6161]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9572775363922119\n",
      " - softmax probs: tensor([[0.3848, 0.6152]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9550433158874512\n",
      " - softmax probs: tensor([[0.3856, 0.6144]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9528322219848633\n",
      " - softmax probs: tensor([[0.3865, 0.6135]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9506277441978455\n",
      " - softmax probs: tensor([[0.3874, 0.6126]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9484260082244873\n",
      " - softmax probs: tensor([[0.3882, 0.6118]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9462295770645142\n",
      " - softmax probs: tensor([[0.3891, 0.6109]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9440405368804932\n",
      " - softmax probs: tensor([[0.3899, 0.6101]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9418601989746094\n",
      " - softmax probs: tensor([[0.3907, 0.6093]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9397044777870178\n",
      " - softmax probs: tensor([[0.3916, 0.6084]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9375903606414795\n",
      " - softmax probs: tensor([[0.3924, 0.6076]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9354828596115112\n",
      " - softmax probs: tensor([[0.3932, 0.6068]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9334819316864014\n",
      " - softmax probs: tensor([[0.3939, 0.6061]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9316833019256592\n",
      " - softmax probs: tensor([[0.3946, 0.6054]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9298884272575378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.3953, 0.6047]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9280977249145508\n",
      " - softmax probs: tensor([[0.3960, 0.6040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.926306962966919\n",
      " - softmax probs: tensor([[0.3967, 0.6033]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9245222806930542\n",
      " - softmax probs: tensor([[0.3974, 0.6026]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9227567911148071\n",
      " - softmax probs: tensor([[0.3981, 0.6019]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9210798144340515\n",
      " - softmax probs: tensor([[0.3988, 0.6012]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9194084405899048\n",
      " - softmax probs: tensor([[0.3994, 0.6006]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.917740523815155\n",
      " - softmax probs: tensor([[0.4001, 0.5999]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9160783290863037\n",
      " - softmax probs: tensor([[0.4007, 0.5993]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9144265651702881\n",
      " - softmax probs: tensor([[0.4014, 0.5986]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9127810001373291\n",
      " - softmax probs: tensor([[0.4021, 0.5979]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9111391305923462\n",
      " - softmax probs: tensor([[0.4027, 0.5973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9095004200935364\n",
      " - softmax probs: tensor([[0.4034, 0.5966]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.907861053943634\n",
      " - softmax probs: tensor([[0.4040, 0.5960]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9062250852584839\n",
      " - softmax probs: tensor([[0.4047, 0.5953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9045931100845337\n",
      " - softmax probs: tensor([[0.4054, 0.5946]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9029650092124939\n",
      " - softmax probs: tensor([[0.4060, 0.5940]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.9013404846191406\n",
      " - softmax probs: tensor([[0.4067, 0.5933]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8997193574905396\n",
      " - softmax probs: tensor([[0.4073, 0.5927]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8981059193611145\n",
      " - softmax probs: tensor([[0.4080, 0.5920]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8964987993240356\n",
      " - softmax probs: tensor([[0.4087, 0.5913]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.894895076751709\n",
      " - softmax probs: tensor([[0.4093, 0.5907]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8932949304580688\n",
      " - softmax probs: tensor([[0.4100, 0.5900]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.891701877117157\n",
      " - softmax probs: tensor([[0.4106, 0.5894]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8901190757751465\n",
      " - softmax probs: tensor([[0.4113, 0.5887]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8885393738746643\n",
      " - softmax probs: tensor([[0.4119, 0.5881]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.886965274810791\n",
      " - softmax probs: tensor([[0.4126, 0.5874]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.885394275188446\n",
      " - softmax probs: tensor([[0.4132, 0.5868]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8838221430778503\n",
      " - softmax probs: tensor([[0.4138, 0.5862]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8822550773620605\n",
      " - softmax probs: tensor([[0.4145, 0.5855]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8806915283203125\n",
      " - softmax probs: tensor([[0.4151, 0.5849]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8791316747665405\n",
      " - softmax probs: tensor([[0.4158, 0.5842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8775752186775208\n",
      " - softmax probs: tensor([[0.4164, 0.5836]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8760220408439636\n",
      " - softmax probs: tensor([[0.4171, 0.5829]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8744713068008423\n",
      " - softmax probs: tensor([[0.4177, 0.5823]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8729224801063538\n",
      " - softmax probs: tensor([[0.4184, 0.5816]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.871381402015686\n",
      " - softmax probs: tensor([[0.4190, 0.5810]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8698952198028564\n",
      " - softmax probs: tensor([[0.4196, 0.5804]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8684161901473999\n",
      " - softmax probs: tensor([[0.4202, 0.5798]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8669422268867493\n",
      " - softmax probs: tensor([[0.4209, 0.5791]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8654744029045105\n",
      " - softmax probs: tensor([[0.4215, 0.5785]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.864012598991394\n",
      " - softmax probs: tensor([[0.4221, 0.5779]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8625541925430298\n",
      " - softmax probs: tensor([[0.4227, 0.5773]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8610979318618774\n",
      " - softmax probs: tensor([[0.4233, 0.5767]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8596488237380981\n",
      " - softmax probs: tensor([[0.4239, 0.5761]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8582011461257935\n",
      " - softmax probs: tensor([[0.4245, 0.5755]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8567578196525574\n",
      " - softmax probs: tensor([[0.4251, 0.5749]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.855320394039154\n",
      " - softmax probs: tensor([[0.4258, 0.5742]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8538861274719238\n",
      " - softmax probs: tensor([[0.4264, 0.5736]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8523784875869751\n",
      " - softmax probs: tensor([[0.4271, 0.5729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8507280349731445\n",
      " - softmax probs: tensor([[0.4278, 0.5722]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8490596413612366\n",
      " - softmax probs: tensor([[0.4285, 0.5715]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8475067019462585\n",
      " - softmax probs: tensor([[0.4291, 0.5709]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8459582328796387\n",
      " - softmax probs: tensor([[0.4298, 0.5702]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8444139361381531\n",
      " - softmax probs: tensor([[0.4305, 0.5695]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8428735136985779\n",
      " - softmax probs: tensor([[0.4311, 0.5689]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.841336727142334\n",
      " - softmax probs: tensor([[0.4318, 0.5682]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8397439122200012\n",
      " - softmax probs: tensor([[0.4326, 0.5674]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8380347490310669\n",
      " - softmax probs: tensor([[0.4333, 0.5667]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8363310098648071\n",
      " - softmax probs: tensor([[0.4340, 0.5660]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8346481323242188\n",
      " - softmax probs: tensor([[0.4348, 0.5652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8329759836196899\n",
      " - softmax probs: tensor([[0.4355, 0.5645]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8313079476356506\n",
      " - softmax probs: tensor([[0.4362, 0.5638]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8297592997550964\n",
      " - softmax probs: tensor([[0.4368, 0.5632]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8283482789993286\n",
      " - softmax probs: tensor([[0.4374, 0.5626]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8269395232200623\n",
      " - softmax probs: tensor([[0.4380, 0.5620]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8255388736724854\n",
      " - softmax probs: tensor([[0.4386, 0.5614]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8241811394691467\n",
      " - softmax probs: tensor([[0.4392, 0.5608]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8228271007537842\n",
      " - softmax probs: tensor([[0.4398, 0.5602]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8214805722236633\n",
      " - softmax probs: tensor([[0.4404, 0.5596]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8201366662979126\n",
      " - softmax probs: tensor([[0.4410, 0.5590]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8187955021858215\n",
      " - softmax probs: tensor([[0.4415, 0.5585]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8174644112586975\n",
      " - softmax probs: tensor([[0.4421, 0.5579]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8161419630050659\n",
      " - softmax probs: tensor([[0.4427, 0.5573]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8148224949836731\n",
      " - softmax probs: tensor([[0.4433, 0.5567]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8135062456130981\n",
      " - softmax probs: tensor([[0.4439, 0.5561]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8121735453605652\n",
      " - softmax probs: tensor([[0.4445, 0.5555]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8107296228408813\n",
      " - softmax probs: tensor([[0.4452, 0.5548]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8092889785766602\n",
      " - softmax probs: tensor([[0.4458, 0.5542]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8078513145446777\n",
      " - softmax probs: tensor([[0.4465, 0.5535]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8064153790473938\n",
      " - softmax probs: tensor([[0.4471, 0.5529]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8049806356430054\n",
      " - softmax probs: tensor([[0.4477, 0.5523]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.803551971912384\n",
      " - softmax probs: tensor([[0.4484, 0.5516]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.802130937576294\n",
      " - softmax probs: tensor([[0.4490, 0.5510]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.8007126450538635\n",
      " - softmax probs: tensor([[0.4496, 0.5504]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7992967367172241\n",
      " - softmax probs: tensor([[0.4503, 0.5497]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7978858351707458\n",
      " - softmax probs: tensor([[0.4509, 0.5491]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7964805364608765\n",
      " - softmax probs: tensor([[0.4515, 0.5485]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7950769662857056\n",
      " - softmax probs: tensor([[0.4522, 0.5478]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7936769723892212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.4528, 0.5472]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7922804355621338\n",
      " - softmax probs: tensor([[0.4534, 0.5466]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7908868789672852\n",
      " - softmax probs: tensor([[0.4541, 0.5459]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7894243001937866\n",
      " - softmax probs: tensor([[0.4549, 0.5451]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7877610921859741\n",
      " - softmax probs: tensor([[0.4556, 0.5444]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7861050367355347\n",
      " - softmax probs: tensor([[0.4564, 0.5436]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7844641208648682\n",
      " - softmax probs: tensor([[0.4571, 0.5429]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7828282117843628\n",
      " - softmax probs: tensor([[0.4579, 0.5421]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7811974287033081\n",
      " - softmax probs: tensor([[0.4586, 0.5414]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7795717716217041\n",
      " - softmax probs: tensor([[0.4593, 0.5407]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7779698371887207\n",
      " - softmax probs: tensor([[0.4600, 0.5400]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7764385938644409\n",
      " - softmax probs: tensor([[0.4607, 0.5393]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7749125361442566\n",
      " - softmax probs: tensor([[0.4614, 0.5386]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7733902335166931\n",
      " - softmax probs: tensor([[0.4621, 0.5379]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7718714475631714\n",
      " - softmax probs: tensor([[0.4628, 0.5372]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7703568339347839\n",
      " - softmax probs: tensor([[0.4635, 0.5365]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7688410878181458\n",
      " - softmax probs: tensor([[0.4643, 0.5357]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7673247456550598\n",
      " - softmax probs: tensor([[0.4650, 0.5350]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7658134698867798\n",
      " - softmax probs: tensor([[0.4657, 0.5343]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7643164992332458\n",
      " - softmax probs: tensor([[0.4663, 0.5337]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7628925442695618\n",
      " - softmax probs: tensor([[0.4670, 0.5330]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7615306377410889\n",
      " - softmax probs: tensor([[0.4675, 0.5325]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7602581977844238\n",
      " - softmax probs: tensor([[0.4681, 0.5319]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7589929699897766\n",
      " - softmax probs: tensor([[0.4687, 0.5313]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7577356100082397\n",
      " - softmax probs: tensor([[0.4693, 0.5307]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7564812898635864\n",
      " - softmax probs: tensor([[0.4699, 0.5301]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7552332878112793\n",
      " - softmax probs: tensor([[0.4705, 0.5295]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7539893388748169\n",
      " - softmax probs: tensor([[0.4711, 0.5289]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7527447938919067\n",
      " - softmax probs: tensor([[0.4717, 0.5283]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7515034079551697\n",
      " - softmax probs: tensor([[0.4722, 0.5278]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7502670288085938\n",
      " - softmax probs: tensor([[0.4728, 0.5272]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7489967942237854\n",
      " - softmax probs: tensor([[0.4735, 0.5265]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7476649284362793\n",
      " - softmax probs: tensor([[0.4741, 0.5259]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7463967800140381\n",
      " - softmax probs: tensor([[0.4747, 0.5253]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.745133638381958\n",
      " - softmax probs: tensor([[0.4753, 0.5247]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7438743114471436\n",
      " - softmax probs: tensor([[0.4759, 0.5241]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7426175475120544\n",
      " - softmax probs: tensor([[0.4765, 0.5235]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.741361141204834\n",
      " - softmax probs: tensor([[0.4771, 0.5229]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7401062250137329\n",
      " - softmax probs: tensor([[0.4777, 0.5223]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7388546466827393\n",
      " - softmax probs: tensor([[0.4783, 0.5217]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7375888824462891\n",
      " - softmax probs: tensor([[0.4789, 0.5211]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7362149953842163\n",
      " - softmax probs: tensor([[0.4796, 0.5204]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7348434925079346\n",
      " - softmax probs: tensor([[0.4802, 0.5198]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7334753274917603\n",
      " - softmax probs: tensor([[0.4809, 0.5191]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7321107983589172\n",
      " - softmax probs: tensor([[0.4815, 0.5185]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7307491898536682\n",
      " - softmax probs: tensor([[0.4822, 0.5178]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7293910980224609\n",
      " - softmax probs: tensor([[0.4829, 0.5171]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7280386686325073\n",
      " - softmax probs: tensor([[0.4835, 0.5165]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7266937494277954\n",
      " - softmax probs: tensor([[0.4842, 0.5158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7253520488739014\n",
      " - softmax probs: tensor([[0.4848, 0.5152]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7240138053894043\n",
      " - softmax probs: tensor([[0.4854, 0.5146]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7226790189743042\n",
      " - softmax probs: tensor([[0.4861, 0.5139]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7213467955589294\n",
      " - softmax probs: tensor([[0.4867, 0.5133]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7200183272361755\n",
      " - softmax probs: tensor([[0.4874, 0.5126]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.718693733215332\n",
      " - softmax probs: tensor([[0.4880, 0.5120]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7173798084259033\n",
      " - softmax probs: tensor([[0.4887, 0.5113]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7160702347755432\n",
      " - softmax probs: tensor([[0.4893, 0.5107]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7147651314735413\n",
      " - softmax probs: tensor([[0.4899, 0.5101]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7134659290313721\n",
      " - softmax probs: tensor([[0.4906, 0.5094]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7121721506118774\n",
      " - softmax probs: tensor([[0.4912, 0.5088]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.710882842540741\n",
      " - softmax probs: tensor([[0.4918, 0.5082]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7095990180969238\n",
      " - softmax probs: tensor([[0.4925, 0.5075]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7083181142807007\n",
      " - softmax probs: tensor([[0.4931, 0.5069]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7070440053939819\n",
      " - softmax probs: tensor([[0.4937, 0.5063]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.705775797367096\n",
      " - softmax probs: tensor([[0.4944, 0.5056]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7045025825500488\n",
      " - softmax probs: tensor([[0.4950, 0.5050]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7032336592674255\n",
      " - softmax probs: tensor([[0.4956, 0.5044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7019680738449097\n",
      " - softmax probs: tensor([[0.4962, 0.5038]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.7007052302360535\n",
      " - softmax probs: tensor([[0.4969, 0.5031]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6993582844734192\n",
      " - softmax probs: tensor([[0.4976, 0.5024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6978908777236938\n",
      " - softmax probs: tensor([[0.4984, 0.5016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6964267492294312\n",
      " - softmax probs: tensor([[0.4991, 0.5009]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6949664950370789\n",
      " - softmax probs: tensor([[0.4998, 0.5002]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6935154795646667\n",
      " - softmax probs: tensor([[0.5005, 0.4995]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6920698285102844\n",
      " - softmax probs: tensor([[0.5013, 0.4987]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6906284689903259\n",
      " - softmax probs: tensor([[0.5020, 0.4980]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6891908645629883\n",
      " - softmax probs: tensor([[0.5027, 0.4973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.687724232673645\n",
      " - softmax probs: tensor([[0.5035, 0.4965]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6862001419067383\n",
      " - softmax probs: tensor([[0.5042, 0.4958]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6846990585327148\n",
      " - softmax probs: tensor([[0.5050, 0.4950]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6832234859466553\n",
      " - softmax probs: tensor([[0.5057, 0.4943]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6817587614059448\n",
      " - softmax probs: tensor([[0.5065, 0.4935]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6803023815155029\n",
      " - softmax probs: tensor([[0.5072, 0.4928]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6788508892059326\n",
      " - softmax probs: tensor([[0.5079, 0.4921]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6774045825004578\n",
      " - softmax probs: tensor([[0.5087, 0.4913]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6759644150733948\n",
      " - softmax probs: tensor([[0.5094, 0.4906]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6745412349700928\n",
      " - softmax probs: tensor([[0.5101, 0.4899]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6731358766555786\n",
      " - softmax probs: tensor([[0.5108, 0.4892]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6717345118522644\n",
      " - softmax probs: tensor([[0.5115, 0.4885]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6703360080718994\n",
      " - softmax probs: tensor([[0.5123, 0.4877]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.668939471244812\n",
      " - softmax probs: tensor([[0.5130, 0.4870]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6675467491149902\n",
      " - softmax probs: tensor([[0.5137, 0.4863]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6661571264266968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.5144, 0.4856]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6647697687149048\n",
      " - softmax probs: tensor([[0.5151, 0.4849]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6633902192115784\n",
      " - softmax probs: tensor([[0.5158, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.662014901638031\n",
      " - softmax probs: tensor([[0.5167, 0.4833]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6603065729141235\n",
      " - softmax probs: tensor([[0.5176, 0.4824]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6584601998329163\n",
      " - softmax probs: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6566203236579895\n",
      " - softmax probs: tensor([[0.5196, 0.4804]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6547882556915283\n",
      " - softmax probs: tensor([[0.5205, 0.4795]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6529027223587036\n",
      " - softmax probs: tensor([[0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6509362459182739\n",
      " - softmax probs: tensor([[0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6489155888557434\n",
      " - softmax probs: tensor([[0.5237, 0.4763]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6467618346214294\n",
      " - softmax probs: tensor([[0.5249, 0.4751]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6446197628974915\n",
      " - softmax probs: tensor([[0.5260, 0.4740]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6424944400787354\n",
      " - softmax probs: tensor([[0.5271, 0.4729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6403726935386658\n",
      " - softmax probs: tensor([[0.5282, 0.4718]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6382615566253662\n",
      " - softmax probs: tensor([[0.5293, 0.4707]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6361615061759949\n",
      " - softmax probs: tensor([[0.5304, 0.4696]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6340692043304443\n",
      " - softmax probs: tensor([[0.5315, 0.4685]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6319858431816101\n",
      " - softmax probs: tensor([[0.5326, 0.4674]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6299120783805847\n",
      " - softmax probs: tensor([[0.5337, 0.4663]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6278484463691711\n",
      " - softmax probs: tensor([[0.5348, 0.4652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6257947683334351\n",
      " - softmax probs: tensor([[0.5359, 0.4641]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6237507462501526\n",
      " - softmax probs: tensor([[0.5370, 0.4630]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6217203140258789\n",
      " - softmax probs: tensor([[0.5381, 0.4619]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6197052001953125\n",
      " - softmax probs: tensor([[0.5392, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6177019476890564\n",
      " - softmax probs: tensor([[0.5403, 0.4597]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6157108545303345\n",
      " - softmax probs: tensor([[0.5413, 0.4587]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6137294769287109\n",
      " - softmax probs: tensor([[0.5424, 0.4576]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6117558479309082\n",
      " - softmax probs: tensor([[0.5435, 0.4565]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6097913384437561\n",
      " - softmax probs: tensor([[0.5445, 0.4555]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.6078352928161621\n",
      " - softmax probs: tensor([[0.5456, 0.4544]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.605888307094574\n",
      " - softmax probs: tensor([[0.5466, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.603950560092926\n",
      " - softmax probs: tensor([[0.5477, 0.4523]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.601990282535553\n",
      " - softmax probs: tensor([[0.5488, 0.4512]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5999783873558044\n",
      " - softmax probs: tensor([[0.5499, 0.4501]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5979772806167603\n",
      " - softmax probs: tensor([[0.5510, 0.4490]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5959868431091309\n",
      " - softmax probs: tensor([[0.5521, 0.4479]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5940119028091431\n",
      " - softmax probs: tensor([[0.5532, 0.4468]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.592048704624176\n",
      " - softmax probs: tensor([[0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5900976657867432\n",
      " - softmax probs: tensor([[0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5881673693656921\n",
      " - softmax probs: tensor([[0.5564, 0.4436]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5862449407577515\n",
      " - softmax probs: tensor([[0.5575, 0.4425]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5843337774276733\n",
      " - softmax probs: tensor([[0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5824405550956726\n",
      " - softmax probs: tensor([[0.5596, 0.4404]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5805617570877075\n",
      " - softmax probs: tensor([[0.5606, 0.4394]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5787006616592407\n",
      " - softmax probs: tensor([[0.5617, 0.4383]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5768518447875977\n",
      " - softmax probs: tensor([[0.5627, 0.4373]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5750154852867126\n",
      " - softmax probs: tensor([[0.5637, 0.4363]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5731881856918335\n",
      " - softmax probs: tensor([[0.5648, 0.4352]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5713698267936707\n",
      " - softmax probs: tensor([[0.5658, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5695630311965942\n",
      " - softmax probs: tensor([[0.5668, 0.4332]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5677662491798401\n",
      " - softmax probs: tensor([[0.5678, 0.4322]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5659834146499634\n",
      " - softmax probs: tensor([[0.5688, 0.4312]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5642107725143433\n",
      " - softmax probs: tensor([[0.5698, 0.4302]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5624458193778992\n",
      " - softmax probs: tensor([[0.5708, 0.4292]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5606874227523804\n",
      " - softmax probs: tensor([[0.5718, 0.4282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5589286088943481\n",
      " - softmax probs: tensor([[0.5728, 0.4272]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5571672320365906\n",
      " - softmax probs: tensor([[0.5738, 0.4262]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.555418848991394\n",
      " - softmax probs: tensor([[0.5748, 0.4252]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5536798238754272\n",
      " - softmax probs: tensor([[0.5758, 0.4242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5519509315490723\n",
      " - softmax probs: tensor([[0.5768, 0.4232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5502325892448425\n",
      " - softmax probs: tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5485364198684692\n",
      " - softmax probs: tensor([[0.5788, 0.4212]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.54685378074646\n",
      " - softmax probs: tensor([[0.5797, 0.4203]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5451878905296326\n",
      " - softmax probs: tensor([[0.5807, 0.4193]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5435620546340942\n",
      " - softmax probs: tensor([[0.5815, 0.4185]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5420595407485962\n",
      " - softmax probs: tensor([[0.5824, 0.4176]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5405645370483398\n",
      " - softmax probs: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5390744805335999\n",
      " - softmax probs: tensor([[0.5842, 0.4158]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5375910997390747\n",
      " - softmax probs: tensor([[0.5850, 0.4150]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5361111164093018\n",
      " - softmax probs: tensor([[0.5859, 0.4141]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5346360206604004\n",
      " - softmax probs: tensor([[0.5867, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5331668853759766\n",
      " - softmax probs: tensor([[0.5876, 0.4124]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5317051410675049\n",
      " - softmax probs: tensor([[0.5885, 0.4115]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.530250608921051\n",
      " - softmax probs: tensor([[0.5894, 0.4106]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5286905765533447\n",
      " - softmax probs: tensor([[0.5903, 0.4097]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5271375179290771\n",
      " - softmax probs: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5255908966064453\n",
      " - softmax probs: tensor([[0.5922, 0.4078]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5239896178245544\n",
      " - softmax probs: tensor([[0.5931, 0.4069]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5224025249481201\n",
      " - softmax probs: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5208237767219543\n",
      " - softmax probs: tensor([[0.5950, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.51925128698349\n",
      " - softmax probs: tensor([[0.5959, 0.4041]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5176881551742554\n",
      " - softmax probs: tensor([[0.5968, 0.4032]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5161383152008057\n",
      " - softmax probs: tensor([[0.5977, 0.4023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5145982503890991\n",
      " - softmax probs: tensor([[0.5987, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5130271911621094\n",
      " - softmax probs: tensor([[0.5997, 0.4003]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5113725662231445\n",
      " - softmax probs: tensor([[0.6007, 0.3993]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5097312331199646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - softmax probs: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5080899596214294\n",
      " - softmax probs: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5063087940216064\n",
      " - softmax probs: tensor([[0.6038, 0.3962]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5045418739318848\n",
      " - softmax probs: tensor([[0.6048, 0.3952]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5027884244918823\n",
      " - softmax probs: tensor([[0.6059, 0.3941]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.5009651780128479\n",
      " - softmax probs: tensor([[0.6070, 0.3930]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.49915724992752075\n",
      " - softmax probs: tensor([[0.6082, 0.3918]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4973319172859192\n",
      " - softmax probs: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4955177903175354\n",
      " - softmax probs: tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4937140941619873\n",
      " - softmax probs: tensor([[0.6115, 0.3885]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4919208288192749\n",
      " - softmax probs: tensor([[0.6125, 0.3875]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.490140825510025\n",
      " - softmax probs: tensor([[0.6136, 0.3864]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4883716106414795\n",
      " - softmax probs: tensor([[0.6147, 0.3853]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4866209626197815\n",
      " - softmax probs: tensor([[0.6158, 0.3842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.48489058017730713\n",
      " - softmax probs: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4831743836402893\n",
      " - softmax probs: tensor([[0.6179, 0.3821]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.48150765895843506\n",
      " - softmax probs: tensor([[0.6189, 0.3811]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.479839563369751\n",
      " - softmax probs: tensor([[0.6199, 0.3801]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4781847894191742\n",
      " - softmax probs: tensor([[0.6209, 0.3791]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.47653818130493164\n",
      " - softmax probs: tensor([[0.6220, 0.3780]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4748648405075073\n",
      " - softmax probs: tensor([[0.6230, 0.3770]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4731341600418091\n",
      " - softmax probs: tensor([[0.6241, 0.3759]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.47141265869140625\n",
      " - softmax probs: tensor([[0.6252, 0.3748]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.46969175338745117\n",
      " - softmax probs: tensor([[0.6263, 0.3737]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.467979371547699\n",
      " - softmax probs: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4662752151489258\n",
      " - softmax probs: tensor([[0.6284, 0.3716]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4645865857601166\n",
      " - softmax probs: tensor([[0.6294, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.46291300654411316\n",
      " - softmax probs: tensor([[0.6305, 0.3695]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4612520933151245\n",
      " - softmax probs: tensor([[0.6315, 0.3685]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4597043991088867\n",
      " - softmax probs: tensor([[0.6324, 0.3676]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4581684470176697\n",
      " - softmax probs: tensor([[0.6334, 0.3666]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.45664048194885254\n",
      " - softmax probs: tensor([[0.6344, 0.3656]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.45511969923973083\n",
      " - softmax probs: tensor([[0.6353, 0.3647]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.45360738039016724\n",
      " - softmax probs: tensor([[0.6363, 0.3637]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.45210570096969604\n",
      " - softmax probs: tensor([[0.6372, 0.3628]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4506154954433441\n",
      " - softmax probs: tensor([[0.6382, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4490882158279419\n",
      " - softmax probs: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.44743794202804565\n",
      " - softmax probs: tensor([[0.6403, 0.3597]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4457426369190216\n",
      " - softmax probs: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4440619647502899\n",
      " - softmax probs: tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4423946738243103\n",
      " - softmax probs: tensor([[0.6436, 0.3564]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.44073760509490967\n",
      " - softmax probs: tensor([[0.6446, 0.3554]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.43909043073654175\n",
      " - softmax probs: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.43746012449264526\n",
      " - softmax probs: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.435840904712677\n",
      " - softmax probs: tensor([[0.6478, 0.3522]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4342275559902191\n",
      " - softmax probs: tensor([[0.6488, 0.3512]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.43262287974357605\n",
      " - softmax probs: tensor([[0.6498, 0.3502]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.43103262782096863\n",
      " - softmax probs: tensor([[0.6509, 0.3491]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.42945384979248047\n",
      " - softmax probs: tensor([[0.6519, 0.3481]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4278891980648041\n",
      " - softmax probs: tensor([[0.6529, 0.3471]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.42629510164260864\n",
      " - softmax probs: tensor([[0.6540, 0.3460]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.42466041445732117\n",
      " - softmax probs: tensor([[0.6551, 0.3449]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4230339229106903\n",
      " - softmax probs: tensor([[0.6561, 0.3439]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4214138686656952\n",
      " - softmax probs: tensor([[0.6572, 0.3428]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.41980376839637756\n",
      " - softmax probs: tensor([[0.6582, 0.3418]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4182063937187195\n",
      " - softmax probs: tensor([[0.6593, 0.3407]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.41662657260894775\n",
      " - softmax probs: tensor([[0.6603, 0.3397]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4150606095790863\n",
      " - softmax probs: tensor([[0.6613, 0.3387]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4135054349899292\n",
      " - softmax probs: tensor([[0.6624, 0.3376]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.41195541620254517\n",
      " - softmax probs: tensor([[0.6634, 0.3366]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.41040992736816406\n",
      " - softmax probs: tensor([[0.6644, 0.3356]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.40887612104415894\n",
      " - softmax probs: tensor([[0.6654, 0.3346]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4073546826839447\n",
      " - softmax probs: tensor([[0.6664, 0.3336]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4058414101600647\n",
      " - softmax probs: tensor([[0.6674, 0.3326]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4043377637863159\n",
      " - softmax probs: tensor([[0.6684, 0.3316]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.4028444290161133\n",
      " - softmax probs: tensor([[0.6694, 0.3306]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.40136393904685974\n",
      " - softmax probs: tensor([[0.6704, 0.3296]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.39989227056503296\n",
      " - softmax probs: tensor([[0.6714, 0.3286]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.39843112230300903\n",
      " - softmax probs: tensor([[0.6723, 0.3277]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3969864249229431\n",
      " - softmax probs: tensor([[0.6733, 0.3267]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.39555248618125916\n",
      " - softmax probs: tensor([[0.6743, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3941287398338318\n",
      " - softmax probs: tensor([[0.6752, 0.3248]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.39271458983421326\n",
      " - softmax probs: tensor([[0.6762, 0.3238]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.39131391048431396\n",
      " - softmax probs: tensor([[0.6771, 0.3229]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.38992103934288025\n",
      " - softmax probs: tensor([[0.6780, 0.3220]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.38853776454925537\n",
      " - softmax probs: tensor([[0.6790, 0.3210]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.38716229796409607\n",
      " - softmax probs: tensor([[0.6799, 0.3201]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3858019709587097\n",
      " - softmax probs: tensor([[0.6808, 0.3192]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3844652771949768\n",
      " - softmax probs: tensor([[0.6817, 0.3183]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3831349015235901\n",
      " - softmax probs: tensor([[0.6826, 0.3174]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.38181746006011963\n",
      " - softmax probs: tensor([[0.6835, 0.3165]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.38051316142082214\n",
      " - softmax probs: tensor([[0.6844, 0.3156]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.37922555208206177\n",
      " - softmax probs: tensor([[0.6853, 0.3147]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3779453635215759\n",
      " - softmax probs: tensor([[0.6861, 0.3139]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.376674085855484\n",
      " - softmax probs: tensor([[0.6870, 0.3130]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3754134476184845\n",
      " - softmax probs: tensor([[0.6879, 0.3121]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3741597831249237\n",
      " - softmax probs: tensor([[0.6887, 0.3113]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3729163408279419\n",
      " - softmax probs: tensor([[0.6896, 0.3104]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.37167951464653015\n",
      " - softmax probs: tensor([[0.6904, 0.3096]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3704491853713989\n",
      " - softmax probs: tensor([[0.6913, 0.3087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.36922815442085266\n",
      " - softmax probs: tensor([[0.6921, 0.3079]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.3680158853530884\n",
      " - softmax probs: tensor([[0.6929, 0.3071]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3668132424354553\n",
      " - softmax probs: tensor([[0.6938, 0.3062]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3656214773654938\n",
      " - softmax probs: tensor([[0.6946, 0.3054]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.36443811655044556\n",
      " - softmax probs: tensor([[0.6954, 0.3046]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3632631003856659\n",
      " - softmax probs: tensor([[0.6962, 0.3038]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3621075451374054\n",
      " - softmax probs: tensor([[0.6970, 0.3030]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.36096200346946716\n",
      " - softmax probs: tensor([[0.6978, 0.3022]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3598308563232422\n",
      " - softmax probs: tensor([[0.6986, 0.3014]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3587058484554291\n",
      " - softmax probs: tensor([[0.6994, 0.3006]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3575884997844696\n",
      " - softmax probs: tensor([[0.7001, 0.2999]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.35647866129875183\n",
      " - softmax probs: tensor([[0.7009, 0.2991]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.35537487268447876\n",
      " - softmax probs: tensor([[0.7017, 0.2983]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.35427671670913696\n",
      " - softmax probs: tensor([[0.7024, 0.2976]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3531891405582428\n",
      " - softmax probs: tensor([[0.7032, 0.2968]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3521084487438202\n",
      " - softmax probs: tensor([[0.7040, 0.2960]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3510344326496124\n",
      " - softmax probs: tensor([[0.7047, 0.2953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.34996864199638367\n",
      " - softmax probs: tensor([[0.7055, 0.2945]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.34890809655189514\n",
      " - softmax probs: tensor([[0.7062, 0.2938]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3478495180606842\n",
      " - softmax probs: tensor([[0.7070, 0.2930]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.34679269790649414\n",
      " - softmax probs: tensor([[0.7077, 0.2923]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3457414507865906\n",
      " - softmax probs: tensor([[0.7084, 0.2916]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3447001278400421\n",
      " - softmax probs: tensor([[0.7092, 0.2908]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3436712324619293\n",
      " - softmax probs: tensor([[0.7099, 0.2901]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3426523804664612\n",
      " - softmax probs: tensor([[0.7106, 0.2894]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.34162673354148865\n",
      " - softmax probs: tensor([[0.7113, 0.2887]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.34060558676719666\n",
      " - softmax probs: tensor([[0.7121, 0.2879]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3396033048629761\n",
      " - softmax probs: tensor([[0.7127, 0.2873]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.33869919180870056\n",
      " - softmax probs: tensor([[0.7133, 0.2867]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3378037214279175\n",
      " - softmax probs: tensor([[0.7140, 0.2860]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.33691221475601196\n",
      " - softmax probs: tensor([[0.7146, 0.2854]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.33602532744407654\n",
      " - softmax probs: tensor([[0.7152, 0.2848]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3351421356201172\n",
      " - softmax probs: tensor([[0.7159, 0.2841]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3342633545398712\n",
      " - softmax probs: tensor([[0.7165, 0.2835]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3333881199359894\n",
      " - softmax probs: tensor([[0.7171, 0.2829]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.33251672983169556\n",
      " - softmax probs: tensor([[0.7177, 0.2823]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3316507637500763\n",
      " - softmax probs: tensor([[0.7184, 0.2816]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3307950496673584\n",
      " - softmax probs: tensor([[0.7190, 0.2810]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.32994362711906433\n",
      " - softmax probs: tensor([[0.7196, 0.2804]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.32910075783729553\n",
      " - softmax probs: tensor([[0.7202, 0.2798]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3282615840435028\n",
      " - softmax probs: tensor([[0.7208, 0.2792]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.32742515206336975\n",
      " - softmax probs: tensor([[0.7214, 0.2786]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3265726864337921\n",
      " - softmax probs: tensor([[0.7220, 0.2780]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3257271647453308\n",
      " - softmax probs: tensor([[0.7226, 0.2774]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.32488566637039185\n",
      " - softmax probs: tensor([[0.7232, 0.2768]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3240514397621155\n",
      " - softmax probs: tensor([[0.7238, 0.2762]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.32322561740875244\n",
      " - softmax probs: tensor([[0.7244, 0.2756]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3224056363105774\n",
      " - softmax probs: tensor([[0.7250, 0.2750]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3215892016887665\n",
      " - softmax probs: tensor([[0.7256, 0.2744]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3207763433456421\n",
      " - softmax probs: tensor([[0.7262, 0.2738]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3199675381183624\n",
      " - softmax probs: tensor([[0.7268, 0.2732]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.319161981344223\n",
      " - softmax probs: tensor([[0.7273, 0.2727]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.31836068630218506\n",
      " - softmax probs: tensor([[0.7279, 0.2721]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.3175663948059082\n",
      " - softmax probs: tensor([[0.7285, 0.2715]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      " - loss: 0.31677621603012085\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    bad_image.grad = None\n",
    "\n",
    "    y_pred = model(bad_image.unsqueeze(0))\n",
    "    print(f' - softmax probs: {torch.softmax(y_pred, dim=1)}')\n",
    "\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(f' - loss: {loss}')\n",
    "    loss.backward()\n",
    "\n",
    "    bad_image.data -= lr * bad_image.grad\n",
    "\n",
    "    if y_pred[0][0] > 0.5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAASsUlEQVR4nO3dbYxUZZYH8P+B4v0dkbYFlDeNkI2AINmoWd2YNaBG4MOswwfCRrPMhzGZMfNhjX4YE2NCNjszmQ+bSZqVDLOZdTJGiBjHcRBRMzEgrSIvyyqsaYeG5k2UKd5pOPuhLzst9j2np566dQvP/5d0urpOPVVP3arTt26d+zyPqCqI6NtvQNkdIKLGYLITBcFkJwqCyU4UBJOdKIhKIx9swIABOmAA/78QFeXy5cu4fPmy9BVLSnYRWQTg5wAGAvgPVV1t3X7AgAEYNWpUykOWRqTP7QegZwOX9dger7Sact/9aZ9S2k29b6t90dulrJJ2tVrNjdW8mxWRgQD+HcBiALMBLBeR2bXeHxEVK+Uz9UIA+1X1M1W9AOA3AJbUp1tEVG8pyT4JwIFef3dm132NiKwSkXYRaS/64y4R5Us5Zu/roOYbByqq2gagDQAqlQrPzSUqScqevRPAlF5/TwZwKK07RFSUlGTfDuAWEZkmIoMBfBfAxvp0i4jqreaP8araLSJPAHgDPaW3taq6p24960NqOSSFVUops18er29Fl5isuHfORWp5LOU1+zaOBpVGPqlKpaIpdfZmTfZrGZO9tsduVtVqFd3d3X0+OZ7ORhQEk50oCCY7URBMdqIgmOxEQTDZiYJo6Hh2oLhySGqZxotbZaKU8lPRUktMXnmszPEORZZii37eKcNva8U9O1EQTHaiIJjsREEw2YmCYLITBcFkJwqi4aW3osolRY9iSikZFj2D66VLl2pumzq1d6Viv4Wsx7948WLSfVvPG0grlxZZWisL9+xEQTDZiYJgshMFwWQnCoLJThQEk50oCCY7URANr7OXJXUm06La9qd9Sq3cq0WPGTPGjM+ZM8eMT5482YwvXLgwN/bOO++Ybdvb28344cOHzXiZQ4uLXiW2FtyzEwXBZCcKgslOFASTnSgIJjtREEx2oiCY7ERBNFWdvcgVQT0pdc+ix9J7tXJr3LfXdubMmWb80UcfNeODBg0y49brsmzZMrPtuXPnzPiBAwfMuDce3tKMdfJUSckuIh0AqgAuAehW1QX16BQR1V899ux/r6rH63A/RFQgHrMTBZGa7ArgDyLygYis6usGIrJKRNpFpL3MpYKIokv9GH+3qh4SkYkANonI/6jqu71voKptANoAoFKplDcygSi4pD27qh7Kfh8FsAFA/hAnIipVzckuIiNEZNSVywAeALC7Xh0jovpK+RjfAmBDVm+sAPgvVf19SmdS5l8veu526/sG77sIr9adMi88ALS0tOTGFi9ebLadPn26Ge/u7jbjkyZNMuOvvfZabuzNN9802x48eNCMe+dWeNvNUnQdvYyx9jUnu6p+BsCe2YCImgZLb0RBMNmJgmCyEwXBZCcKgslOFERTDXFNUfQSvFaZx7tvr3zltZ82bZoZX7JkSW5s2LBhZtvRo0eb8bFjx5rxN954w4y/+uqrubHjx+3xU95281jlM+++vaG71yLu2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIK6pOrtVN02d+tdrf/HixZrv+9ZbbzXjixYtMuMDBw4048OHD8+N3XjjjWbbcePGmfGNGzea8ffee8+MW+cneOcAeOcfTJw40YzfdNNNubFt27aZbc+fP2/GPSlTmxc1/JV7dqIgmOxEQTDZiYJgshMFwWQnCoLJThQEk50oiGuqzm5JXbLZqqN7rrvuOjP+wAMP1HzfADB06NCaH/+jjz4y27799ttm/OzZs2b85MmTZtwaL3/77bebbe+8804zPnv2bDNuvabedrlw4YIZ984BSKmVF7VcNPfsREEw2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQ35o6e2rds1KxN4U1z/iMGTPMtt6Y8SFDhpjxw4cPm/H3338/N7Zz506zrXd+gTeW3ptf/YYbbsiNrVixwmzr6ezsNONr1qzJjXnPO3X+A2+5aGu7FrVctLtnF5G1InJURHb3um68iGwSkX3Zb/vdTESl68/H+F8CuHoqlacAbFbVWwBszv4moibmJruqvgvgxFVXLwGwLru8DsDS+naLiOqt1mP2FlXtAgBV7RKR3MnARGQVgFXZ5RofjohSFf4Fnaq2AWgDgEqlUsxMekTkqrX0dkREWgEg+320fl0ioiLUmuwbAazMLq8E8Ep9ukNERXE/xovIiwDuAzBBRDoB/BjAagC/FZHHAfwJwHfq0Zkij+lT66ZW+9bWVrPthAkTzLhXL37ppZfM+IkTV39/+hcjRoww2545c8aMe/XoWbNmmfH58+fnxnbt2mW27ejoMOPenPXWWPzUtd+98zK895MV9+ZmqHWsvJvsqro8J3R/TY9IRKXg6bJEQTDZiYJgshMFwWQnCoLJThREw4e4WiUsb5hqkaU577GtoZzetMPz5s0z4175K+V5nz592oyPGjXKjFtTQQPAuXPnzPhbb72VG/NKSF7pzZvCO6W85b2m3tBfT8ry47Xinp0oCCY7URBMdqIgmOxEQTDZiYJgshMFwWQnCqLhdXarhlhkHd2ri3rLIg8fPjw3Vq1WzbbeMNN7773XjH/66adm/PXXX8+NHTt2zGzr1dm9Or1Xj77++utzY4cOHTLbjhw5MumxrVq6d36AV4f3hsh67+WUOn2tdXju2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIKSosbN9qVQq6tV1a5UydS/gL5s8bNiw3NjEibmrXwHwl3ReunSpGfeWRd6+fXtubOvWrWbbzz//3IwPHjzYjJ8/f96MW+cgnDp1ymzrLXXtbRerlu3126uje/GUqclTVKtVdHd393nn3LMTBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREE0fDy7JWVZZa+u6Y0f9tpbddnjx4+bbb154T/++GMz7s2PPn369NyYd/6AN47fG/ftjTm3+n7zzTebba3nBQBbtmwx45MmTcqNeeP8vbH23hwGKe9lbw0Db6x9bjvvBiKyVkSOisjuXtc9KyIHRWRH9vNgTY9ORA3Tn38RvwSwqI/rf6aqc7Of39W3W0RUb26yq+q7AE40oC9EVKCUL+ieEJGd2cf83JOYRWSViLSLSLt3LEJExak12X8BYAaAuQC6APwk74aq2qaqC1R1Qa1fLBBRupqyT1WPqOolVb0MYA2AhfXtFhHVW03JLiKtvf5cBmB33m2JqDm4dXYReRHAfQAmiEgngB8DuE9E5gJQAB0AvldcF7/Wl9xY6iGCV0+26vRejd77ruLSpUtm/IsvvjDj48ePz42lnn9w8uRJM37x4kUzftttt+XGFi3qq8jzFw8//LAZf+6558z4k08+mRs7cOCA2dZ7Tbz3m9e+yPdyHjfZVXV5H1e/UEBfiKhA/MaMKAgmO1EQTHaiIJjsREEw2YmCuKamkrbKFSlDCoG0JXq98pVXhqlU7KKI99xWrlyZG/OGz3olx/b29qT21jDTqVOnmm3vueceM7569Woz3tnZmRubO3eu2dabptobtuy9Ztb7LSUnOZU0ETHZiaJgshMFwWQnCoLJThQEk50oCCY7URBNNZV0itTzBbxauMVbvje1Du+dA2BNezxnzhyzrbd0cUdHhxn3nrtVhz948KDZ1psqev78+Wb8+eefz4098sgjZtsNGzaYcW8p65T3U1HLPXPPThQEk50oCCY7URBMdqIgmOxEQTDZiYJgshMF0VR19iLH1qfed8pYem+8uldH9+ItLS25sVmzZpltv/zySzOeutS1xavRW+PRAb9vVvuHHnrIbLt9+3YzfuTIETOeMpV0rXV0D/fsREEw2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQTVVn96TUdL1atbesckrt01vW2KvJjhw50ozv3bs3N/bYY4+Zbb3loL15/o8ePWrGL1y4kBvzxoR7r/fkyZNrbr9//36z7VdffWXGT58+bcaHDBlixhu5XsMV7p5dRKaIyBYR2Ssie0TkB9n140Vkk4jsy36PK767RFSr/nyM7wbwI1WdBeBvAXxfRGYDeArAZlW9BcDm7G8ialJusqtql6p+mF2uAtgLYBKAJQDWZTdbB2BpQX0kojr4q47ZRWQqgHkAtgFoUdUuoOcfgohMzGmzCsCq7HJSZ4modv3+Nl5ERgJ4GcAPVfXP/W2nqm2qukBVF3hfkhFRcfqVfSIyCD2J/mtVXZ9dfUREWrN4KwD7a1kiKpX7MV56Pnu/AGCvqv60V2gjgJUAVme/Xymkh/3kHSJ4pTVvuKTVPnXq3xEjRiS1t8pAW7duNdt65av777/fjG/evNmMW9NFjx071mx71113mfE77rjDjFer1dzYJ598YrY9ceKEGfeGLRdZyq21bNefY/a7AawAsEtEdmTXPY2eJP+tiDwO4E8AvlNTD4ioIdxkV9U/Asj7N2T/2yeipsFvzIiCYLITBcFkJwqCyU4UBJOdKAhp5FC7SqWi3pDJWhV9Kq5VN00dPuvV+L3nNnz48NyYNcQUAJ555hkzPmbMGDPuDc89e/ZsbuzMmTNmW29o8KBBg8y41bf169fnxgC/Du9Ng506fbjFytlqtYru7u4+3zDcsxMFwWQnCoLJThQEk50oCCY7URBMdqIgmOxEQTS8zj569OjceJlLNqfEvZpp6jkAXnurb97z8mr83nj2mTNnmnFrzLp3DoDXN2sKbQDYs2dPbmzfvn1m29TXtMjzPlhnJyITk50oCCY7URBMdqIgmOxEQTDZiYJgshMF0VTj2VPGhac+j9S531OkrpRjbRdvvHnqWHxvzLk17tsb8506N7vVPvX19M4BSJHyXmadnYiY7ERRMNmJgmCyEwXBZCcKgslOFASTnSiI/qzPPgXArwDcAOAygDZV/bmIPAvgnwEcy276tKr+LqUzXt00pf6YOv7YeuzU+/aet8eqlafW0b32Q4cONeNend/i1dm994P13Ip8P/SnfRn6sz57N4AfqeqHIjIKwAcisimL/UxV/6247hFRvfRnffYuAF3Z5aqI7AUwqeiOEVF9/VXH7CIyFcA8ANuyq54QkZ0islZExuW0WSUi7SLSnvpxlYhq1+9z40VkJIB3ADyvqutFpAXAcQAK4DkArar6mHUfqWu9FXnMnvLYzXzM7kn9nsR7bs16zF72vIGWUs+NF5FBAF4G8GtVXZ916IiqXlLVywDWAFhYcw+JqHBuskvPv6gXAOxV1Z/2ur61182WAdhd/+4RUb3059v4uwGsALBLRHZk1z0NYLmIzEXPx/gOAN9L7UyR5a/UqaSLWmIXKPYQI3Xor9e3lKWJyzy8KfrQK/X9WIT+fBv/RwB99Typpk5EjcUz6IiCYLITBcFkJwqCyU4UBJOdKAgmO1EQ/amzN0yR9ehmHHJ4RerztuJF1/hTToct+hyAIk9ZLWtJ5pTH5p6dKAgmO1EQTHaiIJjsREEw2YmCYLITBcFkJwqioUs2i8gxAJ/3umoCeqa2akbN2rdm7RfAvtWqnn27WVWv7yvQ0GT/xoOLtKvqgtI6YGjWvjVrvwD2rVaN6hs/xhMFwWQnCqLsZG8r+fEtzdq3Zu0XwL7VqiF9K/WYnYgap+w9OxE1CJOdKIhSkl1EFonIJyKyX0SeKqMPeUSkQ0R2icgOEWkvuS9rReSoiOzudd14EdkkIvuy332usVdS354VkYPZttshIg+W1LcpIrJFRPaKyB4R+UF2fanbzuhXQ7Zbw4/ZRWQggE8B/AOATgDbASxX1f9uaEdyiEgHgAWqWvoJGCLydwBOAfiVqv5Ndt2/Ajihqquzf5TjVPVfmqRvzwI4VfYy3tlqRa29lxkHsBTAP6HEbWf06x/RgO1Wxp59IYD9qvqZql4A8BsAS0roR9NT1XcBnLjq6iUA1mWX16HnzdJwOX1rCqrapaofZperAK4sM17qtjP61RBlJPskAAd6/d2J5lrvXQH8QUQ+EJFVZXemDy2q2gX0vHkATCy5P1dzl/FupKuWGW+abVfL8uepykj2vibQaqb6392qegeAxQC+n31cpf75BYAZAOYC6ALwkzI7ky0z/jKAH6rqn8vsS2999Ksh262MZO8EMKXX35MBHCqhH31S1UPZ76MANqD5lqI+cmUF3ez30ZL78/+aaRnvvpYZRxNsuzKXPy8j2bcDuEVEponIYADfBbCxhH58g4iMyL44gYiMAPAAmm8p6o0AVmaXVwJ4pcS+fE2zLOOdt8w4St52pS9/rqoN/wHwIHq+kf9fAM+U0Yecfk0H8HH2s6fsvgF4ET0f6y6i5xPR4wCuA7AZwL7s9/gm6tt/AtgFYCd6Equ1pL7dg55Dw50AdmQ/D5a97Yx+NWS78XRZoiB4Bh1REEx2oiCY7ERBMNmJgmCyEwXBZCcKgslOFMT/AQP/DMMrSxONAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(bad_image[0].detach().cpu(), cmap='gray')\n",
    "plt.savefig('images/zero-adversarial.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7290651798248291, 0.2709348201751709)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.eval()\n",
    "y_hat = model(bad_image[:, None].to(device))\n",
    "outputs = torch.exp(F.log_softmax(y_hat, dim=1))\n",
    "outputs[0][0].item(), outputs[0][1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_predict(model, device, X, T=1000):\n",
    "    model = model.train()\n",
    "    outputs = torch.zeros(T, 2).to(device)\n",
    "\n",
    "    for i in range(T):\n",
    "        y_hat = model(X[:, None].to(device))\n",
    "        outputs[i] = F.log_softmax(y_hat, dim=1)\n",
    "    \n",
    "    return torch.exp(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "mcs = mc_predict(model, device, bad_image, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = torch.mode(mcs.argmax(axis=1))[0]\n",
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(874, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_mode = torch.sum(mcs.argmax(axis=1) == mode)\n",
    "n_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1260, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max = 0.5 when classes are sampled equally likely\n",
    "# min = 0   when only a single class is sampled\n",
    "variation_ratio = 1. - n_mode.type(torch.float)/T\n",
    "variation_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4714, device='cuda:0', grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min = 0  when only a single class is sampled\n",
    "# max = 0.5  when classes are sampled equally likely\n",
    "-torch.sum(mcs.mean(axis=0)*torch.log(mcs.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
